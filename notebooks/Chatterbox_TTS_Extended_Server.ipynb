{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé§ Chatterbox TTS Server for Stockpile\n",
        "\n",
        "**One-click setup** - Just run the cell below!\n",
        "\n",
        "### Before running:\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí **T4 GPU**\n",
        "2. Click the play button below (or Shift+Enter)\n",
        "3. Wait ~3 minutes for setup\n",
        "4. Copy the URL and paste into Stockpile\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title üöÄ Run This Cell - One Click Setup\n",
        "print(\"=\"*60)\n",
        "print(\"üé§ CHATTERBOX TTS SERVER SETUP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: Install Dependencies\n",
        "# ============================================================\n",
        "print(\"\\nüì¶ Step 1/4: Installing packages...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def run_cmd(cmd, desc):\n",
        "    print(f\"   {desc}\")\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"   ‚ö†Ô∏è Warning: {result.stderr[:200] if result.stderr else 'Unknown error'}\")\n",
        "    return result.returncode == 0\n",
        "\n",
        "# Install chatterbox from working fork\n",
        "run_cmd('pip install -q \"chatterbox-tts @ git+https://github.com/devnen/chatterbox.git@master\"', \"Installing Chatterbox TTS...\")\n",
        "run_cmd('pip install -q fastapi uvicorn python-multipart pyngrok', \"Installing server dependencies...\")\n",
        "\n",
        "print(\"   ‚úÖ Packages installed\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: Load Model\n",
        "# ============================================================\n",
        "print(\"\\nüß† Step 2/4: Loading TTS model (this takes ~2 min)...\")\n",
        "import torch\n",
        "from chatterbox.tts import ChatterboxTTS\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"   Device: {device.upper()}\")\n",
        "\n",
        "if device == \"cpu\":\n",
        "    print(\"   ‚ö†Ô∏è WARNING: No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
        "\n",
        "model = ChatterboxTTS.from_pretrained(device=device)\n",
        "print(\"   ‚úÖ Model loaded\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: Create Server\n",
        "# ============================================================\n",
        "print(\"\\nüñ•Ô∏è Step 3/4: Creating API server...\")\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import tempfile\n",
        "import torchaudio\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import Response\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional\n",
        "\n",
        "app = FastAPI(title=\"Chatterbox TTS Server\")\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class TTSRequest(BaseModel):\n",
        "    text: str\n",
        "    exaggeration: float = 0.5\n",
        "    cfg_weight: float = 0.5\n",
        "    temperature: float = 0.8\n",
        "    output_format: str = \"mp3\"\n",
        "    voice_reference: Optional[str] = None\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"status\": \"running\", \"model\": \"Chatterbox TTS\"}\n",
        "\n",
        "@app.get(\"/api/ui/initial-data\")\n",
        "async def health():\n",
        "    return {\"status\": \"ok\", \"device\": device}\n",
        "\n",
        "@app.post(\"/tts\")\n",
        "async def generate_tts(request: TTSRequest):\n",
        "    try:\n",
        "        text = request.text.strip()\n",
        "        if not text:\n",
        "            raise HTTPException(status_code=400, detail=\"Text required\")\n",
        "        \n",
        "        print(f\"Generating: {len(text)} chars\")\n",
        "        \n",
        "        audio_prompt = None\n",
        "        if request.voice_reference:\n",
        "            try:\n",
        "                audio_bytes = base64.b64decode(request.voice_reference)\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
        "                    f.write(audio_bytes)\n",
        "                    audio_prompt = f.name\n",
        "            except Exception as e:\n",
        "                print(f\"Voice ref error: {e}\")\n",
        "        \n",
        "        wav = model.generate(\n",
        "            text=text,\n",
        "            audio_prompt_path=audio_prompt,\n",
        "            exaggeration=request.exaggeration,\n",
        "            cfg_weight=request.cfg_weight,\n",
        "            temperature=request.temperature,\n",
        "        )\n",
        "        \n",
        "        buffer = io.BytesIO()\n",
        "        torchaudio.save(buffer, wav, model.sr, format=\"mp3\")\n",
        "        buffer.seek(0)\n",
        "        \n",
        "        print(f\"Done: {buffer.getbuffer().nbytes} bytes\")\n",
        "        return Response(content=buffer.read(), media_type=\"audio/mpeg\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "print(\"   ‚úÖ Server created\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: Start Server + Tunnel\n",
        "# ============================================================\n",
        "print(\"\\nüåê Step 4/4: Starting server and tunnel...\")\n",
        "\n",
        "import threading\n",
        "import time\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Start uvicorn in background thread\n",
        "def run_server():\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8004, log_level=\"warning\")\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "time.sleep(3)\n",
        "\n",
        "# Setup ngrok tunnel (more reliable than cloudflared)\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8004).public_url\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ TTS SERVER READY!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüìã Copy this URL into Stockpile:\\n\")\n",
        "print(f\"   {public_url}\")\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"\\n‚ö° Features:\")\n",
        "print(\"   ‚Ä¢ No character limit - generate 10+ minute audio\")\n",
        "print(\"   ‚Ä¢ Voice cloning supported\")\n",
        "print(f\"   ‚Ä¢ GPU accelerated ({device.upper()})\")\n",
        "print(\"\\n‚ö†Ô∏è  Keep this notebook running while using Stockpile!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Keep alive\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(60)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nServer stopped.\")"
      ],
      "outputs": []
    }
  ]
}
