# stockpile config
# copy this file to .env and fill in your values

# required API key
GEMINI_API_KEY=

# ============================================================
# YOUTUBE DATA API (Outlier Finder Enhancement)
# ============================================================
# Enables 50x faster metadata fetching and proper subscriber filtering
# Get your API key at: https://console.cloud.google.com/
# 1. Create a project
# 2. Enable "YouTube Data API v3"
# 3. Create an API key under "Credentials"
# Free quota: 10,000 units/day (~29 topic searches with 100 channels each)
YOUTUBE_API_KEY=
USE_YOUTUBE_API=true

# ============================================================
# TURSO CLOUD DATABASE (Channel Index)
# ============================================================
# Cloud-based SQLite for storing channel index across sessions
# Sign up at: https://turso.tech/
# Run: turso db create stockpile-outliers
# Run: turso db tokens create stockpile-outliers
TURSO_DATABASE_URL=
TURSO_AUTH_TOKEN=
USE_CLOUD_CACHE=false

# ============================================================
# CLOUDFLARE R2 STORAGE (Exports)
# ============================================================
# Store exported CSVs/JSONs in cloud storage
# Set up at: https://dash.cloudflare.com/ -> R2 Object Storage
R2_ACCOUNT_ID=
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET_NAME=stockpile-exports
R2_PUBLIC_URL=

# ============================================================
# REDDIT INTEGRATION (Viral Video Discovery)
# ============================================================
# Enhances outlier finder with Reddit social signals
# Optional: Uses public API if not set (lower rate limits)
# For higher limits, create an app at: https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=
REDDIT_CLIENT_SECRET=
ENABLE_REDDIT_DISCOVERY=true
REDDIT_SUBREDDITS=videos,mealtimevideos,Documentaries

# input sources (local required)
LOCAL_INPUT_FOLDER=input
GOOGLE_DRIVE_INPUT_FOLDER_ID=

# output destinations (local required)
LOCAL_OUTPUT_FOLDER=output
GOOGLE_DRIVE_OUTPUT_FOLDER_ID=

# email notifications (optional)
NOTIFICATION_EMAIL=

# models
WHISPER_MODEL=base
GEMINI_MODEL=gemini-3-flash-preview

# google API (required if using Google Drive and/or you want email notifications)
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=

# processing settings
MAX_VIDEOS_PER_PHRASE=3
MAX_VIDEO_DURATION_SECONDS=900
MAX_VIDEO_SIZE_MB=80

# timeline-aware B-roll planning
# Target number of B-roll clips per minute of input video
# Example: 2 clips/min = 20 B-roll needs for a 10 minute video
CLIPS_PER_MINUTE=2

# interactive mode settings
# Maximum number of AI-generated context questions to ask in interactive mode
INTERACTIVE_MAX_QUESTIONS=3

# clip extraction settings
CLIP_EXTRACTION_ENABLED=true
MIN_CLIP_DURATION=4
MAX_CLIP_DURATION=15
MAX_CLIPS_PER_VIDEO=3
DELETE_ORIGINAL_AFTER_EXTRACTION=true

# two-pass download optimization
# download low-quality preview first, then only download needed clips in high quality
# provides 3-4x speed improvement and 85% bandwidth savings
USE_TWO_PASS_DOWNLOAD=true

# preview quality for AI analysis (lower = faster download)
# options: 144, 240, 360, 480
PREVIEW_MAX_HEIGHT=360

# high-quality clip format
# default: 1080p max with best audio
CLIP_DOWNLOAD_FORMAT=bestvideo[height<=1080]+bestaudio/best

# S2 IMPROVEMENT: AI response caching (100% cost savings on re-runs)
# Caches Gemini API responses keyed by content hash to avoid redundant API calls
# Great for development/testing and re-processing videos with same content
AI_CACHE_ENABLED=true

# Cache time-to-live in days (how long to keep cached responses)
# Increase for stable prompts, decrease if prompts change frequently
AI_CACHE_TTL_DAYS=30

# Maximum cache size in GB (older entries evicted when limit reached)
# 1GB typically holds ~10,000 cached responses
AI_CACHE_MAX_SIZE_GB=1.0

# Cache directory (relative to project root)
AI_CACHE_DIR=.cache/ai_responses

# Parallel processing settings (Phase 2 Performance Optimization)
# Maximum concurrent B-roll needs to process simultaneously
MAX_CONCURRENT_NEEDS=5

# Maximum concurrent video downloads per need
# Higher values = faster but more memory/bandwidth usage
PARALLEL_DOWNLOADS=3

# Maximum concurrent clip extractions (FFmpeg processes)
# Higher values = faster but more CPU usage
PARALLEL_EXTRACTIONS=2

# Maximum concurrent AI API calls
# Higher values = faster but may hit rate limits
PARALLEL_AI_CALLS=5

# Cost tracking and budget management
# Budget limit in USD (optional - set to 0 to disable)
# Warning will be logged if processing costs exceed this limit
BUDGET_LIMIT_USD=10.0

# S5: Video pre-filtering before downloads
# Filters videos based on metadata to avoid wasting bandwidth on poor quality videos
# Minimum view count - videos with fewer views are skipped (often low quality)
MIN_VIEW_COUNT=1000

# Maximum duration for pre-filtering (in seconds)
# Videos longer than this are skipped before download
MAX_PREFILTER_DURATION=600

# Prefer Creative Commons licensed content when available
PREFER_CREATIVE_COMMONS=true

# Blocked keywords in video titles (comma-separated)
# Videos with these keywords in the title are skipped
# Common low-quality patterns: compilations, reactions, rankings, watermarked previews
BLOCKED_TITLE_KEYWORDS=compilation,top 10,reaction,review,explained,tutorial,watermark,watermarked,stock preview,preview only

# Q4: Context-aware video evaluation
# Seconds of transcript context to extract around each B-roll timestamp
# Higher values = more context but may dilute relevance
# Lower values = more focused but may miss important context
EVALUATION_CONTEXT_SECONDS=30.0

# S3: faster-whisper configuration for transcription
# Device for transcription: "auto", "cpu", or "cuda" (for GPU)
WHISPER_DEVICE=auto
# Compute type: "auto", "int8", "float16", or "float32"
# int8 is fastest, float32 is most accurate
WHISPER_COMPUTE_TYPE=auto

# Q3: Multi-source video search (Pexels, Pixabay)
# Adds professional CC0-licensed stock footage sources alongside YouTube
# Free API keys available from respective websites

# Pexels API key - get free at https://www.pexels.com/api/
PEXELS_API_KEY=

# Pixabay API key - get free at https://pixabay.com/api/docs/
PIXABAY_API_KEY=

# Comma-separated list of enabled sources (order determines priority)
# Options: youtube, pexels, pixabay
SEARCH_SOURCES=youtube,pexels,pixabay

# Treat all sources equally - AI decides which clip is best
# When false, sources are searched in order listed in SEARCH_SOURCES
# When true, Pexels/Pixabay results are ranked higher (prioritizes CC0 footage)
PREFER_STOCK_FOOTAGE=false

# Semantic Matching Settings
# Required similarity score (0.0-1.0) for clips to pass verification
# Scores above this threshold indicate strong semantic alignment with B-roll needs
# 0.9 = 90% similarity required (strict matching)
# 0.75 = 75% similarity required (more permissive)
SEMANTIC_MATCH_THRESHOLD=0.9

# Enable semantic verification stage after clip extraction
# When enabled, extracted clips are analyzed for semantic alignment with B-roll needs
# Can significantly improve clip quality but adds processing time
SEMANTIC_VERIFICATION_ENABLED=true

# Reject clips below threshold (true) or warn only (false)
# When true: clips below SEMANTIC_MATCH_THRESHOLD are discarded
# When false: clips are kept but marked as low-confidence
REJECT_BELOW_THRESHOLD=true

# Minimum fraction of required elements that must be present (0.0-1.0)
# Used by semantic verification to ensure key visual elements are captured
# 0.8 = 80% of required elements must be present in the extracted clip
# Higher values enforce stricter quality standards
MIN_REQUIRED_ELEMENTS_MATCH=0.8

# ============================================================
# IMAGE ACQUISITION SETTINGS
# ============================================================
# Parallel image acquisition - downloads one stock image per N seconds of video
# Images are acquired in parallel with video clips for visual aids/B-roll stills

# Enable or disable image acquisition (default: true)
IMAGE_ACQUISITION_ENABLED=true

# Seconds between image acquisition points (default: 5.0)
# Example: 5.0 = one image every 5 seconds of video
#          For a 60s video: 12 images
IMAGE_INTERVAL_SECONDS=5.0

# Comma-separated list of image sources to search (order determines fallback priority)
# Options: google, pexels, pixabay, openverse, duckduckgo
# google requires GOOGLE_CSE_API_KEY + GOOGLE_CSE_CX (100 free queries/day)
# pexels/pixabay use existing API keys (PEXELS_API_KEY, PIXABAY_API_KEY)
# openverse works without auth (100/day), or with auth (10,000/day)
# duckduckgo is free emergency fallback (no API key, aggressive rate limits)
IMAGE_SOURCES=google,pexels,pixabay,openverse,duckduckgo

# Maximum concurrent image downloads (default: 10)
# Higher values = faster acquisition but more API calls
PARALLEL_IMAGE_DOWNLOADS=10

# Google Custom Search Engine for Google Images (replaces SerpAPI)
# 100 free queries/day (3,000/month) - 30x more than SerpAPI free tier
# Setup:
# 1. Create a Programmable Search Engine: https://programmablesearchengine.google.com/
#    - Enable "Search the entire web" and "Image search"
#    - Copy the Search Engine ID (cx)
# 2. Get an API key: https://console.cloud.google.com/
#    - Enable "Custom Search API"
#    - Create credentials -> API key
GOOGLE_CSE_API_KEY=
GOOGLE_CSE_CX=

# Openverse authentication (optional - for higher rate limits)
# Without auth: 100 requests/day | With auth: 10,000 requests/day
# Register at: https://api.openverse.org/v1/auth_tokens/register/
OPENVERSE_CLIENT_ID=
OPENVERSE_CLIENT_SECRET=

# ============================================================
# FEATURE 1: STYLE/MOOD DETECTION
# ============================================================
# Analyze source video to detect visual style, topic, and audience
# Passes this context to all B-roll selection to ensure style consistency

# Enable style detection (default: true)
# When enabled, AI analyzes transcript to understand video topic, target audience,
# and preferred visual style, then uses this to improve B-roll selection
STYLE_DETECTION_ENABLED=true

# ============================================================
# FEATURE 2: CONTEXT WINDOW
# ============================================================
# Use ±10 seconds of transcript around each B-roll timestamp for better relevance

# Seconds of context to include before and after each B-roll timestamp
# Default: 10.0 (captures ±10 seconds of surrounding transcript)
# Higher values provide more context but may dilute relevance
CONTEXT_WINDOW_SECONDS=10.0

# ============================================================
# FEATURE 3: FEEDBACK LOOP
# ============================================================
# Learn from user rejections to improve future B-roll selections

# Enable feedback loop (default: true)
# Records user rejections and learns patterns to avoid in future selections
FEEDBACK_ENABLED=true

# Directory to store feedback data (default: .stockpile)
# Feedback is stored as JSON and persists between sessions
FEEDBACK_DIR=.stockpile

# ============================================================
# SOURCE PREFERENCES (SOFT BIAS)
# ============================================================
# These settings add a slight preference for specific content sources
# AI uses these as tie-breakers when comparing content of similar quality

# Preferred source for video clips: youtube, pexels, or pixabay
# Default: youtube (more authentic, real-world footage)
VIDEO_PREFERRED_SOURCE=youtube

# Preferred source for images: google, pexels, or pixabay
# Default: google (more variety via web search)
IMAGE_PREFERRED_SOURCE=google

# ============================================================
# TTS (TEXT-TO-SPEECH) SETTINGS
# ============================================================

# Option 1: RunPod Serverless (Recommended - always available, pay-per-use)
# Deploy the worker from stockpile/runpod-tts-worker/ to RunPod Serverless
# Cost: ~$0.03-0.05 per 10 minutes of audio
#
# Get API key from: https://runpod.io/console/user/settings
# Get endpoint ID after deploying: https://runpod.io/console/serverless
RUNPOD_API_KEY=
RUNPOD_ENDPOINT_ID=

# Option 2: Colab Server (Free - requires browser tab open)
# Run the Chatterbox-TTS-Server notebook and paste the URL here
# Get the URL by running: https://github.com/devnen/Chatterbox-TTS-Server
# The notebook provides a public URL via ngrok or cloudflared
TTS_SERVER_URL=

# ============================================================
# AI IMAGE GENERATION
# ============================================================

# Runware AI (cheapest image generation)
# Sign up at: https://runware.ai
# Get API key from dashboard
# Models: runware-flux-klein-4b ($0.0006/img), runware-flux-klein-9b ($0.00078/img), runware-z-image ($0.0006/img)
RUNWARE_API_KEY=

# Qwen Image 2.0 (RunPod - $0.02/image)
# Uses RunPod public endpoint by default (qwen-image-t2i)
# For custom Qwen-Image-2.0 deployment, set your serverless endpoint ID below
# Requires RUNPOD_API_KEY to be set
RUNPOD_QWEN_IMAGE_ENDPOINT_ID=

# Default image generation model
# Options: runware-flux-klein-4b, runware-flux-klein-9b, runware-z-image, gemini-flash, qwen-image
DEFAULT_IMAGE_GEN_MODEL=runware-flux-klein-4b

# Legacy fal.ai key (no longer used, kept for reference)
FAL_API_KEY=